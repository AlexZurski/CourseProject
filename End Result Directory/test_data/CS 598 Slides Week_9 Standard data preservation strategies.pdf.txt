data preservation standard preservation strategies here were view the four classic preservation strategies four common strategies replication make lots of copies distribute them widely migration keep updating your data to new formats as needed emulation maintain software that emulates the original processing normalization convert datasets to standard format optimized for preservation replication pitfalls make lots of copies distribute them widely ensuring authenticity and identity across copies storage costs are nontrivial depending on scale of data independence of replications number of replications each act of replication introduces room for the introduction of errors confusion same data particularly problematic for changes slight or large in encodings most importantly replication does not protect data against technological changes that compromise the viability render ability etc of formats migration pitfalls keep updating your data to new formats as needed every act of transformation introduces room for errors context loss information loss migration is usually ad hoc taking place usually only when needed eg new software tools and often in an emergency when something critical fails migration and migration formats can be uncoordinated and un systematic leading sometimes to datasets in multiple poorly understood lossy overspecialized and incompatible formats and this can lead to confusion about compatibility and scientific equivalence it does not reduce vulnerability to loss as addressed by replication emulation pitfalls maintain software that emulates the original processing highly expensive highly complex how do you identify the properties of any data set program etc that must be maintained the significant properties for which audiences over the long term not all significant properties can be emulated does not address the problems addressed by replication or migration costs mounting emulation environments themselves may need to be preserved in turn normalization convert datasets to standard format optimized for preservation here datasets are maintained in format with standard encodings syntax and ontology and full documentation at all levels for simple datasets this maybe just documented csv files for more complex datasets xml is commonly used along with documentation of both syntax and ontology owl and rdf with corresponding serialization are also used datasets in new or specialized formats can be generated as needed and often suite of tools for transformations to other syntax es or on to logie is maintained normalization pitfalls convert datasets to standard format optimized for preservation some central coordination and support maybe required or atleast rich culture of open development basic protection against loss still required normalization vs migration aspects of normalization the role of transformations are similar to migration but migration as preservation strategy can be distinguished from normalization migration creates chain of datasets with the same data in different formats normalization is hub and spokesmodel we have said that migration formats read hoc uncoordinated often lossy and overspecialized and can lead to compatibility problems but perhaps migration is better integrated into the practical reality of creating new formats for existing data than strategies that require transformation in and out of single core format perhaps but transformations both migration and normalization strategies involve transforming data set in one format to data set in another format both presumably with the same information ideally the transformation as well as the resulting data set should be documented in standard computer process able metadata languages regardless of whether this is migration scenario or normalization scenario the next slide indicates one way this could happen this is also an example of workflow and provenance documentation example of transformation documentation very liberally modified from uiuc medusa record by th bing event version 21 event identifier event identifier type local event identifier type event identifier value medusa 21248 fa 75 ac 45 event identifier value event identifier event type migration event type event date time 20110503 101532 event date time event detail the content dm record xml file was transformed into the mods xml file using xslt event detail linking agent identifier linking agent identifier type uiuc net id linking agent identifier type linking agent identifier value uiuc gni baht linking agent identifier value linking agent identifier linking agent identifier linking agent identifier type filename linking agent identifier type agent identifier value content dm to mods 32 xsl agent identifier value linking agent identifier linking object identifier linking object identifier type filename linking object identifier type linking object identifier value mods xml linking object identifier value linking object identifier linking object identifier linking object identifier type filename linking object identifier type linking object identifier value content dm record xml linking object identifier value linking object identifier event agent version 21 are formatting recorded in computer process able documentation here prem is xml the input and output files are in bold black the xsl file that specifies the transformation is in red documented transformation can support both migration strategy and normalization to see how agent is used to represent software associated with preservation event in this example search fi do in https www loc gov standards premi sv sample records prem is example xml the example is liberally modified from uiuc medusa record
