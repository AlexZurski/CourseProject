probabilistic retrieval model statistical language model cheng xiang department of computer science university of illinois at urbana champaign probabilistic retrieval model statistical language model overview what is language model unigram language model uses of language model what is statistical language model lm probability distribution over word sequences today is wednesday 0001 today wednesday is 00000000000001 the eigenvalue is positive 000001 context dependent can also be regarded as probabilistic mechanism for today is wednesday today wednesday is the eigenvalue is positive why is alm useful quantify the uncertainties in natural language allows us to answer questions like john feels happy habit speech recognition text categorization information retrieval given that user is interested in sports new show likely would the information retrieval the simplest language model uni gram lm generate text by generating each word independently thus pw pw pw parameters pwi pw is voc size text sample drawn according to this word distribution today eigenvalue wednesday pp 0000200010000015 text generation with uni gram lm uni gram lmp text 02 mining 01 association 001 clustering 002 food 000001 topic text mining food 025 nutrition 01 healthy 005 diet 002 topic health document text mining paper food nutrition paper sampling estimation of uni gram lm uni gram lmp text mining paper estimation text 10 mining association database algorithm query efficient text mining association database query total words 100101005100310031001100 is this the best estimate maximum likelihood ml estimator lms for topic representation general background english text the 003 002 is 0015 we 001 food 0003 computer 000001 text 0000006 background lmp wb computer science papers the 0032 0019 is 0014 we 0011 computer 0004 software 00001 text 000006 collection lmp cc the 0031 text 004 mining 0035 association 003 clustering 0005 computer 00009 food 0000001 text mining paper document lmp wd lms for association analysis 10 computer the 0032 0019 is 0014 we 0008 computer 0004 software 00001 topic lmp documents containing word the 003 002 is 0015 we 001 computer 000001 background lmp wb general background english text normalized topic lmp wb computer 400 software 150 program 104 text 30 the 11 099 is 09 we 08 summary language model probability distribution over text unigram language model word distribution uses of language model representing topics discovering word associations 11 additional readings chris manning and in rich sch tze foundations of statistical natural language processing mit press cambridge ma may 1999 rose nfeld two decades of statistical language modeling where do we go from here proceedings of the ieee vol 88 no pp 12701278 aug 200012
