text categorization evaluation part department of computer science university of illinois at urbana champaign overview what is text categorization why text categorization how to do text categorization generative probabilistic models disc rim native approaches how to evaluate categorization results general evaluation methodology have humans to create test collection where every document is generate categorization results using system on the test collection compare the system categorization decisions with the human made categorization decisions and quantify their similarity or equivalently difference the higher the similarity is the better the results are similarity can be measured from different perspectives to understand the quality of results in detail eg which category performs better in general different categorization mistakes may have different cost that inevitably depends on specific applications but it is okay not to consider such cost variation for relative comparison of methods classification accuracy percentage of correct decisions ck yy nd ny nd ny nd human answer correct incorrect yn system result yy esn no total number of decisions made total number of correct decisions classification accuracy problems with classification accuracy some decision errors are more serious than others it maybe more important to get the decisions right on some documents than others it maybe more important to get the decisions right on some categories than other seg spam filtering missing legitimate email costs more than letting spam go problem with imbalanced test set skewed test set 98 in category 12 in category strong baseline put all instances in category 198 accuracy per document evaluation ck yy nd ny nd nn yn how good are the decisions on di system human true positive stp false negative sfn human false positives fp true negatives tn recall does the doc have all the categories it should have precision how many are correct per category evaluation ck yy nd ny nd nn yn how good are the decisions on ci system human true positive stp false negative sfn human false positives fp true negatives tn precision recall how many are correct has the category been assigned to all the docs of this category combine precision and recall measure precision recall parameter often set to why not 05 05 doc pairs
