paradigmatic relation discovery part cheng xiang department of computer science university of illinois at urbana champaign paradigmatic relation discovery real world observed world textdata english perceive express perspective topic mining analysis opinion mining and sentiment analysis text based prediction natural language processing text representation topic mining analysis text based prediction natural language processing and text representation word association mining and analysis cat my eats fish on saturday his eats turkey on tuesday context may contain adjacent or non adjacent words measuring context similarity sim left left sim right right sim window window high sim word word word and word are paradigmatic ally related bag of words vector space model vs word word word nd nca td yn dog vocabulary size vs for paradigmatic relation mining nd xn word word word simd xi yj how to compute each vector many approaches are possible most developed originally for text retrieval expected overlap of words in context eow simd nd yn xi cw id yi cw id 27 probability that two randomly picked words from and respectively are identical total counts of words in count of word wii nd probability that randomly picked word from is wi would eowc work well intuitively it makes sense the more overlap the two context documents have the higher the similarity would be however it favors matching one frequent term very well over matching more distinct terms expected overlap of words in context eow simd nd yn xi cw id yi cw id 22 probability that two randomly picked words from and respectively are identical total counts of words in count of word wii nd probability that randomly picked word from is wi improving eow with retrieval heuristics it favors matching one frequent term very well over matching more distinct terms sub linear transformation of term frequency reward matching rare word idf term weighting transformation cw dt fwd term frequency weighty fwd cw dy 1201 bit vector ignore counts log transformation bm 25 transformation term frequency weighty fw dxc wd 12 very large idf weighting penalizing popular terms idf do cfr eq idf log km log total number of docs in collection total number of docs containing doc frequency adapting bm 25 retrieval model for paradigmatic relation mining simd nd nyi is defined similarly bm 25 can also discover syn tag mati relations idf weighted idf xn idf the highly weighted terms in the context vector of word ware likely syn tag mati call related tow summary main idea for discovering paradigmatic relations collecting the context of candidate word to form pseudo document bag of words computing similarity of the corresponding context documents of two candidate words highly similar word pairs can be assumed to have paradigmatic relations many different ways to implement this general idea text retrieval models can be easily adapted for computing similarity of two context documents bm25 idf weighting represents the state of the art
