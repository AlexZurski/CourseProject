subset selection which variables to keep and which to drop why its task can we just select variables based on their values in the output eg drop all variables which are not at 55 subset selection best subset score each model model subset of variables design search algorithm to the optimal one models election criteria scores for linear regression often take the following form goo complexity penalty the st term is an increasing function of rss and the nd terman increasing function of the number of non intercept variables intercept is always included you can count the intercept in por not it doesnt make any from now on number of non intercept variables popular choices of scores mallows cpr 22 full paa ic log li pb bic log li log np note that when is large adding an additional predictor costs lot more in bic than ic so ict ends to pick bigger model than bi ccp performs similar to ica is estimated from the full model ie the model with all the predictors bin the context of linear regression with normal errors we can replace log li by log rss mallows cp recall the decomposition of the training and tester rore trainer unavoidable err bia set ester unavoidable err bias so tester rrs which is known as mallows cp
