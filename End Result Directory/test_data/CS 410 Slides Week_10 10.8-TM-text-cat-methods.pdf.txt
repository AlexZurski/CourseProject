text categorization methods department of computer science university of illinois at urbana champaign overview what is text categorization why text categorization how to do text categorization generative probabilistic models disc rim native approaches how to evaluate categorization results categorization methods manual determine the category based on rules that are carefully designed to reflect the domain knowledge about the categorization problem works well when the categories are very well defined categories are easily distinguished based on surface features in text eg special vocabulary is known to only occur in particular category sufficient domain knowledge is available to suggest many effective rules problems labor intensive not robust both problems can be solved alleviated by using machine learning use human experts to annotate datasets with category labels training data provide set of features to represent each text object that can potentially use machine learning the training data figure out which features are most useful for separating different categories optimal ly combine the features to minimize the errors of categorization on the training data the trained classifier can then be applied to new text object to predict the most likely category that human expert would assign to it machine learning for text categorization general setup learn classifier xy input all text objects output yall categories learn classifier function xy such that fx yy gives the correct category for xx all methods rely on disc rim native features of text objects to distinguish categories combine multiple features in weighted manner adjust weights on features to minimize errors on the training data different methods tend to vary in their way of measuring the errors on the training data may optimize different objective loss cost function their way of combining features eg linear vs nonlinear generative vs disc rim native classifier generative classifier learn in each category attempt to model px py px and compute pyx based on px and py by using bayes rule objective function is likelihood thus indirectly measuring training errors eg nave bayes disc rim native classifier learn what features separate categories attempt to model pyx directly objective function directly measures errors of categorization on training data eg logistic regression support vector machines mk nearest neighbors kn
