text categorization evaluation part department of computer science university of illinois at urbana champaign macro average overall the categories ck yy nd ny nd ny nd precision recall measure overall precision aggregate overall recall overall score krk fk macro average overall the documents ck yy nd ny nd ny nd precision recall measure overall recall overall score overall precision aggregate pn rn fn micro averaging of precision and recall ck yy nd ny nd ny nd system human true positive stp false negative sfn human false positives fp true negatives tn precision recall first pool all decisions then compute precision and recall sometimes ranking is more appropriate the categorization results are often passed to human for further editing eg correcting system mistakes on news categories prioritizing task grouting an email to the right person for processing in such cases we can evaluate the results as ranked list if the system can give scores for the decisions eg discovery of spam emails often more appropriate to frame the problem as ranking problem instead of categorization problem eg ranking documents in search engine summary of categorization evaluation evaluation is always very important so get it right measures must reflect the intended use of the results for particular application eg spam filtering vs news categorization consider how will the results be further processed by user ideally associate different cost with each different decision error commonly used measures for relative comparison of different methods accuracy precision recall score variations per document per category micro vs macro averaging sometimes ranking maybe more appropriate suggested reading manning chris dpr bha karr agha vanand in rich sch tze introduction to information retrieval cambridge cambridge university press 2007 chapters 1315 yang yi ming 1999 an evaluation of statistical approaches to text categorization in fret 112 may 19996990 doi 101023 10099822202907
