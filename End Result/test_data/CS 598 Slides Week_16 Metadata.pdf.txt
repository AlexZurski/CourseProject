metadata what is metadata first definition the simple and most common colloquial definition is data about data what is metadata better definition structured data about an object that supports functions associated with the designated object greenberg 2003 here the concept of object includes data set the standard classification of metadata by function descriptive for describing are source to support things like finding understanding evaluating choosing among digital objects or data administrative technical preservation rights for decoding and rendering for long term management for describing intellectual property rights structural for relating parts of resources to one another adapted from http www ni so org apps group public download php 17446 understanding 20 metadata pdf conceptual metadata schemas vs their serialization dublin core metadata element set select terms creator william blake title sick rose date 1794 serialized as rdf xml xml namespace href http www org schemas rdf schema as rdf namespace href http www purl org rdf dc as dc rdf rdf rdf description rdf href http purl org metadata dublin core elements dc title the sick rose dc creator william blake dc date 1794 rdf rdf xml serialized with html meta elements meta named title content the sick rose meta named creator content william blake meta named date content 1794 what is being described problems think rbr identifier isbn 9780123751065 author matthew west title developing high quality data models date 2011 publisher morgan kaufman subject database design subject data structures computer science language english pages 389 format pdf identifier http www science direct com science book 9780123751065 identifier isbn 9780123751065 author matthew west title developing high quality data models date 2011 publisher morgan kaufman subject database design subject data structures computer science language english pages 408 metadata is fundamental to data curation area description supported by metadata that documents collection support the collection and acquisition of data method location time instruments settings calibration organization employ an appropriate data model and use appropriate standards schemas and schema documentation for semantics syntax and encoding storage support reliable and effective storage authoritative and alternative copies physical locations redundancy compression reduction backups preservation ensure that data will be understandable and useable in the future see organization identification storage discoverability support the ability to search for and locate relevant data topic coverage formats availability currency access support the ability to retrieve and distributed at see organization security licensing owner location workflow support the ability to systematize data work flows see organization scripts processes transformations inputs identification support the ability to identify authenticate and validate data see organization identifiers version data integrity checks authentication integration support integration of data from different sources using different data models see organization identification access discoverability metadata is fundamental to data curation activity description metadata documenting modification support management of corrections and updates see organization workflow provenance identification reformatting support reformatting for use by different tools or to match new format standards see organization identification workflow provenance support identifying what inputs and calculations are responsible for data values see workflow identification reproducibility reproducibility support ability to reproduce results ensuring scientific validity see organization workflow provenance identification preservation ensure that data will be understandable and useable in the future see organization identification storage compliance ensure compliance to legal regulatory and local policy requirements see organization provenance workflow discoverability certification security ensure that data is secure from tampering or inappropriate access and distribution see organization provenance workflow discoverability encryption certification communication support representation publishing and visualization that provide insight see organization identification reproducibility compliance sharing support sharing data between researchers teams andinstitutions see discoverability organization workflow provenance identification preservation recall our data ontology now ask yourself in successful preservation scenario what exactly is preserved what exactly is preserved no really what 10 preservation is not about preserving anything data preservation is not about preserving the existence of objects it is about communication with the future the best simple definition preservation is ensuring reliable communication with the future 21 reagan moore towards theory of digital preservation the international journal of digital cu ration 20082 simone sacchi what do we mean by preserving digital information towards sound conceptual foundations for digital stewardship doctoral dissertation university of illinois at urbana champaign 201511 the definition expanded preservation is not about preservation preservation is ensuring reliable communication with the future more exactly preservation actions are intended to ensure that future researchers will come into possession of physical media and encodings from which they will correctly recognize the originally intended propositional content and from which they will be justified in believing that this propositional content is in fact the intended propositional content this can be adapted to more explicitly accommodate software agents and automatic processing the key thing is that the process is reliable all interpretations are correct and justified 12 and longer one viable can be read correctly from media render able can be correctly viewed processed executed understandable can be correctly understood authentic table can be correctly determined to be what it purports to be identifiable can be correctly identified andre identified and more can be added of course find able conform ant etc following our own definition of preservation we would emphasize that each of these five not only must be achievable but the user must have justified confidence in the result see premis https www loc gov standards premis 13 four common strategies replication make lots of copies distribute them widely migration keep updating your data to new formats as needed emulation maintain software that emulates the original processing normalization convert datasets to standard format optimized for preservation 14 transformations both migration and normalization strategies involve transforming data set in one format to data set in another format both presumably with the same information ideally the transformation as well as the resulting data set should be documented in standard computer process able metadata languages regardless of whether this is migration scenario or normalization scenario the next slide indicates one way this could happen this is also an example of workflow and provenance documentation 15 example of transformation documentation very liberally modified from uiuc medusa record by th bing event version 21 event identifier event identifier type local event identifier type event identifier value medusa 21248 fa 75 ac 45 event identifier value event identifier event type migration event type event date time 20110503 101532 event date time event detail the content dm record xml file was transformed into the mods xml file using xslt event detail linking agent identifier linking agent identifier type uiuc net id linking agent identifier type linking agent identifier value uiuc gni baht linking agent identifier value linking agent identifier linking agent identifier linking agent identifier type filename linking agent identifier type agent identifier value content dm to mods 32 xsl agent identifier value linking agent identifier linking object identifier linking object identifier type filename linking object identifier type linking object identifier value mods xml linking object identifier value linking object identifier linking object identifier linking object identifier type filename linking object identifier type linking object identifier value content dm record xml linking object identifier value linking object identifier event agent version 21 are formatting recorded in computer process able documentation here prem is xml the input and output files are in bold black the xsl file that specifies the transformation is in red documented transformation can support both migration strategy and normalization to see how agent is used to represent software associated with preservation event in this example search fi do in https www loc gov standards premi sv sample records prem is example xml the example is liberally modified from uiuc medusa record 16 identity and identifiers identification problems in data curation again identification problems archiving is this data set already in the archive preservation was the information preserved in the new file format security has this data set been tampered with authentication is this the data we think it is reproducibility does this xml file have the same information as that json file provenance were these datasets derived from the same data conversions does the converted file have the same data as the original lots of things to be identified we need identifiers for lots of things because without shared identifiers we cannot reliably communicate what we are taking about so persons properties values counties automobiles nations proteins events etc everything 19 so what are we identifying instantiation level semantic level syntax level encoding levels based on the systematic assertion models am for modeling datasets developed by david du binet al for example propositions expressed by rdf triples encoded by rdf xml encoded by unicode characters encoded by utf bitstream inscribed in all mm propositional what are we identifying propositions semantic level symbols syntax level symbols encoding level symbols encoding level symbols encoding level symbols encoding level ne for inscription but operationally identification works from the bottom up we identify the bitstream or character sequence in normal form in order to indirectly identify the higher level encodings syntax or propositional content 21 identifiers for abstraction levels the general problem the things we want to identify can be expressed or encoded in different ways we are typically looking at relationship between propositions and representations representations and encodings encodings and encodings and encoding slather rinse repeat and so we cant easily use the lower level instantiations to determine identity of the upper levels entities in other words variation at the lower level does not necessarily entail variation at the upper levels but there is solution to this problem in the next video actually the relationships are mm because of the arbitrary nature of representation described in the data concepts videos that is depending on conventions like standards and other social circumstances agreements decisions intentions expectations the same eg encoding can encode multiple representations but most of the time in identity problems we can ignore this and rely on shared understanding of the relevant concepts 22 canonical iz ation canonical iz ation is technique for determining representational identity and is reasonable proxy for propositional identity in short if necessary convert to the same representation language and encoding normalize incidental variations test resulting files for byte level identity 23 standards why standards standards are fundamental in data curation standards promote reliable efficient communication with others now and with ourselves in the future supporting integration interoperable tools validation authentication preservation regulatory compliance etc etc etc data format conformance vs processor conformance data standards can define conformance for both data and ii processing data set conformance might require such things as particular character encoding particular delimiters serialization matching particular formal grammar constraints such as referential integrity data types inclusion of relevant metadata processor conformance might require the processing software to correctly token ize verify that statements matcha particular grammar perform additional validation referential integrity data types etc confirm required metadata process datasets correctly eg performing particular actions such as generating normalized parse tree or performing calculations rendering visualization etc displaying an error when processing non conform ant datasets the processor may also be required to halt or it maybe allowed to continue processing conformance maybe tested by specified test suite of datasets data set conformance is tested by validating soft ward
