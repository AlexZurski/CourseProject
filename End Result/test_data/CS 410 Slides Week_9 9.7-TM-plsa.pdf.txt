probabilistic latent semantic analysis plsa department of computer science university of illinois at urbana champaign probabilistic latent semantic analysis pl real world observed world textdata english perceive express perspective topic mining analysis opinion mining and sentiment analysis text based prediction natural language processing text representation topic mining and analysis text based prediction natural language processing and text representation word association mining and analysis document as sample of mixed topics topic to pick topic background government 03 response 02 donate 01 relief 005 help 002 city 02 new 01 orleans 005 the 004 003 criticism of government response to the hurricane primarily consisted of criticism of its response to the approach of the storm and its aftermath specifically in the delayed response to the of the 13 million residents of the greater new orleans metropolitan area evacuated over seventy countries pledged monetary donations or other assistance many applications are possible if we can mining multiple topics from text doc do cndo 112 11121 210222 kn 10 nk 30128 sports 002 game 001 basketball 0005 football 0004 science 004 scientist 003 spaceship 0006 travel 005 attraction 003 trip 001 input kv output ki ik textdata generating text with multiple topics pw topic to pick topic background government 03 response 02 donate 01 relief 005 help 002 city 02 new 01 orleans 005 the 004 003 topic choice pb bp pk dk pw pw pw kp wb bp wb pk pw bp pw 21 bp pw 15 probabilistic latent semantic analysis plsa unknown parameters dj percentage of background words known background lm known coverage of topic indo cdp rob of word win topic how many unknown parameters are there in total ml parameter estimation constrained optimization em algorithm for plsa step probability that wind ocd is generated from topic probability that wind ocd is generated from background use of bayes rule hidden variable topic indicator zd em algorithm for plsa step re estimated probability of do cd covering topic re estimated probability of word for topic ml estimate based on counts to topic hidden variable topic indicator zd computation of the em algorithm initialize all unknown parameters randomly repeat until likelihood converges este pm step 10 for this one in general accumulate counts and then normalize summary plsa mixture model with unigram lms topics adding predetermined background lm helps discover disc rim native topics kword distributions topics proportion of each topic in each document the output can enable many applications clustering of terms and docs treat each to picasa cluster further associate topics with different contexts eg time periods locations authors sources etc 11
