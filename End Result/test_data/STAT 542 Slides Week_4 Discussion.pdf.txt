advantages of ensemble methods based on trees less processing is needed eg na can be handled automatically and no scaling normalization is required can handle large number of predictors gb mv random forest random forest has less number of tuning parameters while gb has more but with proper tuning gb can perform better than random forest categorical predictors each package treats categorical predictors die rent ly maximal 32 levels for random forest and 1024 levels for bmx boost and some python packages only take numerical input 11
