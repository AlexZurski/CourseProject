why is ridge regression shrinkage method suppose the design matrix has on columns tx ip then the ridge estimate prediction is shrinkage version of the ls estimate prediction ls tx ty ty ridge tx ty 11 ty 11 lsy ls lsy ridge ridge 11 yl ortho normal on orthogonal with norm one 16 in case the columns of are not orthogonal we can reformulate the regression on an orthogonal version of known as the principal components analysis or sv similarly we can see that the ridge estimate prediction is shrinkage version of the ls estimate prediction you can skip the next slides 17 consider singular value decomposition sv do fxx pun pd ppv pp where un columns uj for manon basis for xu tui pvp columns vj for manon basis for rp with vtv ip dpp diagonal matrix with diagonal entries dp being the singular values of for ease of exposition we assume np and rank xp therefore dp 018 the geometric interpretation of sv dx pun pd ppv ppm apa unit circle in rp to an ellipse in rn xn pv jp npd ppv ppv jp dj uj 19 consider singular value decomposition sv do fxx pun pd ppv pp where un columns uj for manon basis for xu tui pvp columns uj for manon basis for rp with vtv ip dpp diagonal matrix with diagonal entries dp being the singular values of for ease of exposition we assume np and rank xp therefore dp pca write xf vt where each columns off np ud is the so called principal components and each column of vis the principal component directions of 20 21 write xy ud vy there is one to one correspondence between and and kk kk som in rp ky kk min rp ky fk kk lsd tyl sj jut jy ridge dia gd jd jut ridge jd jd ls so the ridge estimate ridge shrinks the ls estimate ls by the factor jd directions with smaller eigenvalues get more shrinkage 22 the ls prediction fl sudd ut yuu ty px ut yu the ridge prediction fridge udi gd jd jut px jd jut yu so the ridge prediction ridge shrinks the ls prediction yl by factor jd directions with smaller eigenvalues get more shrinkage 23
